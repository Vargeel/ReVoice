{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavenet Demo\n",
    "Demo of our efficient generation implementation.\n",
    "\n",
    "Trains wavenet on a single wav file. Then generates that file, starting from a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named wavenet.utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e7d020e670c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwavenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwavenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named wavenet.utils"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from wavenet.utils import make_batch\n",
    "from wavenet.models import Model, Generator\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs, targets = make_batch('assets/voice.wav')\n",
    "num_time_samples = inputs.shape[1]\n",
    "num_channels = 1\n",
    "gpu_fraction = 1.0\n",
    "\n",
    "model = Model(num_time_samples=num_time_samples,\n",
    "              num_channels=num_channels,\n",
    "              gpu_fraction=gpu_fraction)\n",
    "\n",
    "Audio(inputs.reshape(inputs.shape[1]), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = time()\n",
    "model.train(inputs, targets)\n",
    "toc = time()\n",
    "\n",
    "print('Training took {} seconds.'.format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = Generator(model)\n",
    "\n",
    "# Get first sample of input\n",
    "input_ = inputs[:, 0:1, 0]\n",
    "\n",
    "tic = time()\n",
    "predictions = generator.run(input_, 32000)\n",
    "toc = time()\n",
    "print('Generating took {} seconds.'.format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(predictions, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import fast_gen as fg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize(data):\n",
    "    temp = np.float32(data) - np.min(data)\n",
    "    out = (temp / np.max(temp) - 0.5) * 2\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(path,class_num):\n",
    "    data = wavfile.read(path)[1]\n",
    "\n",
    "    data_ = normalize(data)\n",
    "    if data.shape[0]>10000 and data.shape[0]<300000 :\n",
    "\n",
    "        # data_f = np.sign(data_) * (np.log(1 + 255*np.abs(data_)) / np.log(1 + 255))\n",
    "\n",
    "        bins = np.linspace(-1, 1, 256)\n",
    "        # Quantize inputs.\n",
    "        inputs = np.digitize(data_[0:-1], bins, right=False) - 1\n",
    "        inputs = bins[inputs][None, :, None]\n",
    "\n",
    "        # Encode targets as ints.\n",
    "        targets_pred = (np.digitize(data_[1::], bins, right=False) - 1)[None, :]\n",
    "        target_class = np.zeros(109)\n",
    "        target_class[int(class_num)] = 1\n",
    "        inputs = np.lib.pad(inputs, ((0,0), (0, 300000 - inputs.shape[1]), (0,0)), 'constant',\n",
    "                                 constant_values=(0, 0))\n",
    "        targets_pred = np.lib.pad(targets_pred, ((0,0), (0, 300000 - targets_pred.shape[1])), 'constant',\n",
    "                                 constant_values=(0, 0))\n",
    "        return inputs, targets_pred, target_class\n",
    "    else :\n",
    "        return [], [], []\n",
    "\n",
    "def generate_batches(root_path = 'data/wav48/', indexes = range(0,10)):\n",
    "    inputs = []\n",
    "    target_class = []\n",
    "    target_pred =[]\n",
    "    ns = 0\n",
    "    for path, subdirs, files in os.walk(root_path):\n",
    "        for name in files:\n",
    "            if name[-3:] == 'wav':\n",
    "                if ns in indexes:\n",
    "                    path_to_file = os.path.join(path, name)\n",
    "                    class_num = path[-3:]\n",
    "                    inputs_loc, targets_pred_loc, targets_class_loc = make_batch(path_to_file,class_num)\n",
    "                    if len(inputs_loc)!=0:\n",
    "                        inputs.append(inputs_loc)\n",
    "                        target_pred.append(targets_pred_loc)\n",
    "                        target_class.append(targets_class_loc)\n",
    "                ns += 1\n",
    "\n",
    "\n",
    "    inputs_st = np.vstack(inputs)\n",
    "    target_pred_st = np.vstack(target_pred)\n",
    "    target_class_st = np.vstack(target_class)\n",
    "\n",
    "    return inputs_st,target_pred_st,target_class_st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(b_size = 5):\n",
    "    num_files = 44257\n",
    "    batch_size = b_size\n",
    "    rnd = np.random.permutation(num_files)\n",
    "    for epoch in range(10000):\n",
    "        for iteration in range(num_files/batch_size):\n",
    "            indices = rnd[iteration*batch_size:(iteration +1)*batch_size]\n",
    "            inputs, targets_pred, targets_class  = generate_batches(indexes = indices)\n",
    "            num_time_samples = inputs.shape[1]\n",
    "            num_channels = 1\n",
    "            gpu_fraction = 1.0\n",
    "            model = fg.Model(num_time_samples=num_time_samples,\n",
    "                          num_channels=num_channels,\n",
    "                          gpu_fraction=gpu_fraction)\n",
    "            model.train(inputs, targets_pred, targets_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, targets_pred, targets_class  = generate_batches(indexes = [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
